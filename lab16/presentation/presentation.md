---
## Front matter
lang: ru-RU
title: Лабораторная работа №16
subtitle: Программный RAID (mdadm)
author:
  - Ришард Когенгар
institute:
  - Российский университет дружбы народов, Москва, Россия
date: 22 января 2026

## Formatting pdf
toc: false
slide_level: 2
aspectratio: 169
section-titles: true
theme: metropolis
header-includes:
 - \metroset{progressbar=frametitle,sectionpage=progressbar,numbering=fraction}
---

# Цель работы

## Основная цель

Освоить создание и администрирование программных RAID-массивов в Linux с использованием утилиты **mdadm**.

# Ход выполнения работы

## Создание виртуальных носителей

- Открыт раздел **Носители** в настройках ВМ
- К контроллеру **SATA** добавлены **3 диска по 512 MiB**
- Формат: **VDI**, тип: **динамический**

![Подключение дополнительных виртуальных дисков к контроллеру SATA](Screenshot_1.png){ width=80% }

## Проверка наличия дисков в системе

- Получены права администратора (**root**)
- Проверено появление устройств `/dev/sdd`, `/dev/sde`, `/dev/sdf`

![Проверка наличия добавленных дисков /dev/sdd, /dev/sde, /dev/sdf](Screenshot_2.png){ width=80% }

## Создание разделов на дисках

- На каждом диске создан один раздел:
  - `/dev/sdd1`, `/dev/sde1`, `/dev/sdf1`
- Разметка выполнена утилитой **sfdisk**

![Создание раздела на диске /dev/sdd с помощью sfdisk](Screenshot_3.png){ width=80% }

## Проверка типа разделов и RAID-типы

- Тип новых разделов по умолчанию: **83 (Linux)**
- Просмотр доступных RAID-типов партиций
- Подготовка к включению в RAID

![Проверка типа разделов и изменение на Linux raid autodetect (fd)](Screenshot_4.png){ width=80% }

## Установка типа Linux raid autodetect (fd)

- Тип разделов изменён на **fd**
- Цель: корректная идентификация разделов как RAID-совместимых

![Состояние дисков после изменения типа разделов на fd](Screenshot_5.png){ width=80% }

## Создание RAID 1 массива

- Создан массив **RAID 1**:
  - устройство массива: `/dev/md0`
  - диски: `/dev/sdd1` и `/dev/sde1`
- Выполнена первичная проверка состояния массива

![Создание RAID1 и проверка состояния через /proc/mdstat и mdadm --query](Screenshot_6.png){ width=80% }

## Детальная проверка массива RAID 1

- Массив в состоянии **clean**
- Устройства:
  - `/dev/sdd1` — active sync
  - `/dev/sde1` — active sync

![Детальная информация о массиве md0](Screenshot_7.png){ width=80% }

## Файловая система и монтирование

- Создана файловая система **ext4** на `/dev/md0`
- Монтирование выполнено в каталог `/mnt/raid`

![Создание файловой системы ext4 и монтирование массива](Screenshot_8.png){ width=80% }

## Автомонтирование через /etc/fstab

- Добавлена запись для автомонтирования:
  - устройство: `/dev/md0`
  - точка монтирования: `/mnt/raid`
  - тип: `ext4`, параметры: `defaults 1 2`

![Добавление записи для автомонтирования в /etc/fstab](Screenshot_9.png){ width=80% }

## Имитация отказа и восстановление RAID 1

- Смоделирован отказ `/dev/sde1`
- Сбойный диск удалён из массива
- В массив добавлен третий диск `/dev/sdf1`
- Итог: массив восстановлен и работоспособен

![Имитация отказа, удаление диска и добавление нового устройства в RAID](Screenshot_10.png){ width=80% }

## Остановка массива и очистка метаданных

- Массив размонтирован и остановлен
- Метаданные RAID очищены командой `--zero-superblock`

![Остановка массива и очистка RAID-метаданных](Screenshot_11.png){ width=80% }

## Создание RAID 1 + добавление hotspare

- Создан RAID 1: `/dev/sdd1` + `/dev/sde1` → `/dev/md0`
- Добавлен горячий резерв: `/dev/sdf1` (spare)
- Проверка показывает наличие **2 devices + 1 spare**

![Создание RAID1, добавление hotspare и проверка состояния](Screenshot_12.png){ width=80% }

## Состояние массива с hotspare

- Активные устройства:
  - `/dev/sdd1` — active sync
  - `/dev/sde1` — active sync
- Резервное устройство:
  - `/dev/sdf1` — spare
- Состояние массива: **clean**

![Состояние массива md0: два active sync и один spare](Screenshot_13.png){ width=80% }

## Отказ диска и автоматическая замена hotspare

- Смоделирован отказ `/dev/sde1`
- Hotspare `/dev/sdf1` автоматически перешёл в **active sync**
- Отказавший диск отображается как **faulty**
- Работоспособность массива сохранена

![Имитация отказа диска и автоматическая замена hotspare](Screenshot_14.png){ width=80% }

## Состояние перед преобразованием

- RAID 1 создан на `/dev/sdd1` и `/dev/sde1`
- `/dev/sdf1` добавлен как spare
- Массив корректен и готов к преобразованию

![Проверка состояния массива RAID1 перед преобразованием](Screenshot_16.png){ width=80% }

## Смена уровня массива на RAID 5

- Выполнено преобразование уровня:
  - `--grow --level=5`
- В выводе отображаются параметры RAID 5:
  - layout: **left-symmetric**
  - chunk size: **64K**

![Изменение уровня массива на RAID5 и проверка mdadm --detail](Screenshot_17.png){ width=80% }

## Увеличение числа дисков до 3

- Установлено количество устройств:
  - `--grow --raid-devices=3`
- Все три диска активны (**active sync**)
- Размер массива увеличен (≈ **1020 MiB**)
- Состояние массива: **clean**

![RAID5 после увеличения числа устройств до 3](Screenshot_18.png){ width=80% }

# Итоги работы

## Вывод

- Освоено создание и контроль RAID с помощью **mdadm**
- Создан и проверен **RAID 1** (включая отказ и восстановление)
- Реализован сценарий **hotspare** с автоматической заменой диска
- Выполнено преобразование **RAID 1 → RAID 5** и расширение массива
- Проведена корректная остановка массивов и очистка метаданных
